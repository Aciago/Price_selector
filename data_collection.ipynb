{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29deb1ad-5068-485d-8e44-6accd420a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a199493-df49-43d3-bf18-b9a7a80d2a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PANDAS OPTIONS\n",
    "# Set maximum number of columns and rows to display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Set the maximum column width to a high value\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c368ab5-3088-4775-84c1-daef8da6f5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33c211-9971-4d32-9e14-8cd7d27e3185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdfc7621-dc35-4b93-adaf-cb95cec74873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [01:18<00:00,  1.29s/it]\n",
      "100%|██████████| 61/61 [01:18<00:00,  1.29s/it]\n",
      "100%|██████████| 61/61 [01:19<00:00,  1.31s/it]\n",
      "100%|██████████| 61/61 [01:18<00:00,  1.29s/it]\n",
      "100%|██████████| 61/61 [01:19<00:00,  1.30s/it]\n",
      "100%|██████████| 61/61 [01:19<00:00,  1.30s/it]\n",
      "100%|██████████| 61/61 [01:20<00:00,  1.31s/it]\n",
      "100%|██████████| 61/61 [01:20<00:00,  1.31s/it]\n",
      "100%|██████████| 61/61 [01:19<00:00,  1.31s/it]\n",
      "100%|██████████| 61/61 [01:19<00:00,  1.30s/it]\n",
      "100%|██████████| 61/61 [01:19<00:00,  1.30s/it]\n",
      "100%|██████████| 61/61 [01:20<00:00,  1.32s/it]\n",
      "100%|██████████| 61/61 [01:19<00:00,  1.30s/it]\n",
      "100%|██████████| 61/61 [01:20<00:00,  1.31s/it]\n",
      "100%|██████████| 61/61 [01:19<00:00,  1.30s/it]\n",
      "100%|██████████| 61/61 [01:19<00:00,  1.31s/it]\n",
      "100%|██████████| 61/61 [01:19<00:00,  1.30s/it]\n",
      "100%|██████████| 61/61 [01:19<00:00,  1.30s/it]\n",
      "100%|██████████| 38/38 [00:50<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL to scrape\n",
    "base_url = 'https://www.naturabuy.fr/Munitions-Balles-22LR-cat-884.html'\n",
    "page_number = 1\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('scraped_data.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "# Create a table to store the scraped data\n",
    "c.execute('''\n",
    "CREATE TABLE IF NOT EXISTS products (\n",
    "    product_name TEXT,\n",
    "    product_link TEXT,\n",
    "    manufacturer TEXT,\n",
    "    is_new BOOLEAN,\n",
    "    price FLOAT,\n",
    "    shipping_cost FLOAT,\n",
    "    product_description TEXT\n",
    ")\n",
    "''')\n",
    "conn.commit()\n",
    "\n",
    "# Loop through all pages of the website\n",
    "while True:\n",
    "\n",
    "    # Construct the URL for the current page\n",
    "    url = base_url + f'?PAGE={page_number}'\n",
    "\n",
    "    # Make a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse the HTML content of the response using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all the item cards on the page\n",
    "    cards = soup.find_all('a', class_='itemcard')\n",
    "\n",
    "    # If no cards are found, break out of the loop\n",
    "    if not cards:\n",
    "        break\n",
    "        \n",
    "    # Loop through the item cards and scrape the information\n",
    "    for card in tqdm(cards):\n",
    "\n",
    "        # Get the href attribute of the item card and construct the URL for the product page\n",
    "        product_url = 'https://www.naturabuy.fr/' + card['href'].lstrip('/')\n",
    "\n",
    "        # Make a GET request to the product page\n",
    "        response = requests.get(product_url)\n",
    "\n",
    "        # Parse the HTML content of the response using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Scrape the product name from the title tag\n",
    "        try:\n",
    "            product_name = soup.find('title').text.strip()\n",
    "        except:\n",
    "            product_name = 'N/A'\n",
    "            \n",
    "        # Scrape the manufacturer\n",
    "        try:\n",
    "            manufacturer_element = soup.select_one(\"html:-soup-contains('Marque :') body div#contall div#body_container div#body_container_in div#PAGE div#Columns div#mainProduct div#productWrapper div#blocGallery div#productCriteres div.critere div.criterevalue\")\n",
    "            if manufacturer_element:\n",
    "                manufacturer = manufacturer_element.text.strip().replace(\"Marque :\", \"\")\n",
    "            else:\n",
    "                manufacturer = \"N/A\"\n",
    "        except:\n",
    "            manufacturer = \"N/A\"\n",
    "     \n",
    "        # Scrape whether the item is new or used\n",
    "        try:\n",
    "            item_is_new = soup.find('span', id='availabilityCondition').text.strip()\n",
    "        except:\n",
    "            item_is_new = 'N/A'\n",
    "\n",
    "        # Scrape the price\n",
    "        try:\n",
    "            price = soup.find('div', id='priceContainer').text.strip()\n",
    "        except:\n",
    "            price = 'N/A'\n",
    "\n",
    "        # Scrape the shipping cost\n",
    "        try:\n",
    "            shipping_cost = soup.find('div', id='shippingsContainer').find('b').text.strip()\n",
    "        except:\n",
    "            shipping_cost = 'N/A'\n",
    "            \n",
    "        # Scrape product description\n",
    "        try:\n",
    "            product_description = soup.select_one('div#contall div#body_container div#body_container_in div#PAGE div#Columns div#Description').text.strip()\n",
    "            # Remove '\\n' and '\\xa0'\n",
    "            product_description = product_description.replace('\\n', ' ').replace('\\xa0', ' ')\n",
    "        except:\n",
    "            product_description = 'N/A'\n",
    "\n",
    "        # Insert the scraped data into the database\n",
    "        c.execute('''\n",
    "        INSERT INTO products (product_name, product_link, manufacturer, is_new, price, shipping_cost, product_description)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (product_name, product_url, manufacturer, item_is_new, price, shipping_cost, product_description))\n",
    "        conn.commit()\n",
    "\n",
    "        # Wait for a short time to avoid getting blocked\n",
    "        time.sleep(1)\n",
    "        \n",
    "    # check amount of cards on page, less than 60 leads to end of loop --- last page will have less than max amount of cards\n",
    "    # might be only way for naturabuy site\n",
    "    if len(cards) < 60:\n",
    "        break\n",
    "\n",
    "    # Increment the page number\n",
    "    page_number += 1\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Read the data from the database into a pandas DataFrame and save it to a CSV file\n",
    "conn = sqlite3.connect('scraped_data.db')\n",
    "df = pd.read_sql_query('SELECT * FROM products', conn)\n",
    "df.to_csv('scraped_data.csv', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6ba146-0af4-456a-8019-23b162cdb1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('scraped_data.db')\n",
    "df = pd.read_sql_query('SELECT * FROM products', conn)\n",
    "df.to_csv('scraped_data.csv', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be1b58-662a-4c08-99c0-454dffd25058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL to scrape\n",
    "base_url = 'https://www.naturabuy.fr/Munitions-Balles-22LR-cat-884.html'\n",
    "page_number = 1\n",
    "\n",
    "# Create an empty list to store the scraped data\n",
    "data = []\n",
    "\n",
    "# Loop through all pages of the website\n",
    "while True:\n",
    "\n",
    "    # Construct the URL for the current page\n",
    "    url = base_url + f'?PAGE={page_number}'\n",
    "\n",
    "    # Make a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the HTML content of the response using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all the item cards on the page\n",
    "    cards = soup.find_all('a', class_='itemcard')\n",
    "\n",
    "    # If no cards are found, break out of the loop\n",
    "    if not cards:\n",
    "        break\n",
    "\n",
    "    # Loop through the item cards and scrape the information\n",
    "    for card in cards:\n",
    "\n",
    "        # Get the href attribute of the item card and construct the URL for the product page\n",
    "        product_url = 'https://www.naturabuy.fr/' + card['href'].lstrip('/')\n",
    "\n",
    "        # Make a GET request to the product page\n",
    "        response = requests.get(product_url)\n",
    "\n",
    "        # Parse the HTML content of the response using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        ##### Scrape the product name from the title tag\n",
    "        try:\n",
    "            product_name = soup.find('title').text.strip()\n",
    "        except:\n",
    "            product_name = 'N/A'\n",
    "            \n",
    "       # Scrape the manufacturer\n",
    "        try:\n",
    "            manufacturer_element = soup.select_one(\"html:-soup-contains('Marque :') body div#contall div#body_container div#body_container_in div#PAGE div#Columns div#mainProduct div#productWrapper div#blocGallery div#productCriteres div.critere div.criterevalue\")\n",
    "            if manufacturer_element:\n",
    "                manufacturer = manufacturer_element.text.strip().replace(\"Marque :\", \"\")\n",
    "            else:\n",
    "                manufacturer = \"N/A\"\n",
    "        except:\n",
    "            manufacturer = \"N/A\"\n",
    "     \n",
    "        # Scrape whether the item is new or used\n",
    "        try:\n",
    "            item_is_new = soup.find('span', id='availabilityCondition').text.strip()\n",
    "        except:\n",
    "            item_is_new = 'N/A'\n",
    "\n",
    "        # Scrape the price\n",
    "        try:\n",
    "            price = soup.find('div', id='priceContainer').text.strip()\n",
    "        except:\n",
    "            price = 'N/A'\n",
    "\n",
    "        # Scrape the shipping cost\n",
    "        try:\n",
    "            shipping_cost = soup.find('div', id='shippingsContainer').find('b').text.strip()\n",
    "        except:\n",
    "            shipping_cost = 'N/A'\n",
    "            \n",
    "        # Scrape product description\n",
    "        try:\n",
    "            product_description = soup.select_one('div#contall div#body_container div#body_container_in div#PAGE div#Columns div#Description').text.strip()\n",
    "            # Remove '\\n' and '\\xa0'\n",
    "            product_description = product_description.replace('\\n', ' ').replace('\\xa0', ' ')\n",
    "        except:\n",
    "            product_description = 'N/A'\n",
    "\n",
    "        # Add the scraped data to the list\n",
    "        data.append({\n",
    "            'product_name': product_name,\n",
    "            'product_link': product_url,\n",
    "            'manufacturer': manufacturer,\n",
    "            'is_new': item_is_new,\n",
    "            'price': price,\n",
    "            'shipping_cost': shipping_cost,\n",
    "            'product_description': product_description\n",
    "        })\n",
    "\n",
    "        # Wait for a short time to avoid getting blocked\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Increment the page number\n",
    "    page_number += 1\n",
    "\n",
    "# Convert the list of dictionaries to a pandas DataFrame and save it to a CSV file\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1863b22-25dd-437e-91ce-68fe1a1df11b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the URL to scrape\n",
    "base_url = 'https://www.naturabuy.fr/Munitions-Balles-22LR-cat-884.html'\n",
    "page_number = 1\n",
    "\n",
    "# Create an empty list to store the scraped data\n",
    "data = []\n",
    "\n",
    "# Loop through the first two pages of the website\n",
    "while page_number <= 2:\n",
    "\n",
    "    # Construct the URL for the current page\n",
    "    url = base_url + f'?PAGE={page_number}'\n",
    "\n",
    "    # Make a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the HTML content of the response using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all the item cards on the page\n",
    "    cards = soup.find_all('a', class_='itemcard')\n",
    "\n",
    "    # Loop through the item cards and scrape the information\n",
    "    for card in cards[:5]:\n",
    "\n",
    "        # Get the href attribute of the item card and construct the URL for the product page\n",
    "        product_url = 'https://www.naturabuy.fr/' + card['href'].lstrip('/')\n",
    "\n",
    "        # Make a GET request to the product page\n",
    "        response = requests.get(product_url)\n",
    "\n",
    "        # Parse the HTML content of the response using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        ##### Scrape the product name from the title tag\n",
    "        try:\n",
    "            product_name = soup.find('title').text.strip()\n",
    "        except:\n",
    "            product_name = 'N/A'\n",
    "            \n",
    "       # Scrape the manufacturer\n",
    "        try:\n",
    "            manufacturer_element = soup.select_one(\"html:-soup-contains('Marque :') body div#contall div#body_container div#body_container_in div#PAGE div#Columns div#mainProduct div#productWrapper div#blocGallery div#productCriteres div.critere div.criterevalue\")\n",
    "            if manufacturer_element:\n",
    "                manufacturer = manufacturer_element.text.strip().replace(\"Marque :\", \"\")\n",
    "            else:\n",
    "                manufacturer = \"N/A\"\n",
    "        except:\n",
    "            manufacturer = \"N/A\"\n",
    "     \n",
    "        # Scrape whether the item is new or used\n",
    "        try:\n",
    "            item_is_new = soup.find('span', id='availabilityCondition').text.strip()\n",
    "        except:\n",
    "            item_is_new = 'N/A'\n",
    "\n",
    "        # Scrape the price\n",
    "        try:\n",
    "            price = soup.find('div', id='priceContainer').text.strip()\n",
    "        except:\n",
    "            price = 'N/A'\n",
    "\n",
    "        # Scrape the shipping cost\n",
    "        try:\n",
    "            shipping_cost = soup.find('div', id='shippingsContainer').find('b').text.strip()\n",
    "        except:\n",
    "            shipping_cost = 'N/A'\n",
    "            \n",
    "        # Scrape product description\n",
    "        try:\n",
    "            product_description = soup.select_one('div#contall div#body_container div#body_container_in div#PAGE div#Columns div#Description').text.strip()\n",
    "            # Remove '\\n' and '\\xa0'\n",
    "            product_description = product_description.replace('\\n', ' ').replace('\\xa0', ' ')\n",
    "        except:\n",
    "            product_description = 'N/A'\n",
    "\n",
    "        # Add the scraped data to the list\n",
    "        data.append({\n",
    "            'product_name': product_name,\n",
    "            'product_link': product_url,\n",
    "            'manufacturer': manufacturer,\n",
    "            'is_new': item_is_new,\n",
    "            'price': price,\n",
    "            'shipping_cost': shipping_cost,\n",
    "            'product_description': product_description\n",
    "        })\n",
    "\n",
    "        # Wait for a short time to avoid getting blocked\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Increment the page number\n",
    "    page_number += 1\n",
    "\n",
    "# Convert the list of dictionaries to a pandas DataFrame and save it to a CSV file\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e01d57-06dd-4b47-b54c-cc710ae635fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change dtypes of columns for easier manipulation\n",
    "df['product_name'] = df['product_name'].astype(str)\n",
    "df['manufacturer'] = df['manufacturer'].astype(str)\n",
    "df['is_new'] = df['is_new'].astype(str)\n",
    "df['price'] = df['price'].astype(str)\n",
    "df['shipping_cost'] = df['shipping_cost'].astype(str)\n",
    "\n",
    "# change formatting of prices, remove currency, set as float\n",
    "df['price'] = df['price'].str.replace(',', '.').str.extract('(\\d+\\.\\d+)', expand=False).astype(float)\n",
    "df['shipping_cost'] = df['shipping_cost'].str.replace(',', '.').str.extract('(\\d+\\.\\d+)', expand=False).fillna(0).astype(float)\n",
    "\n",
    "# change string values for new-used to binary\n",
    "df[\"is_new\"] = df[\"is_new\"].map({\"Neuf\": 1, \"Occasion\": 0})\n",
    "\n",
    "# add new column for Total price\n",
    "df['total_price'] = df['price'] + df['shipping_cost']\n",
    "\n",
    "# remove text from description that doesnt belong to the item itself, eg share buttons and shop category\n",
    "df['product_description'] = df['product_description'].apply(lambda x: x.split(\"Flobert > Munitions - Balles 22LR\")[1].strip())\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4ee87-6e2f-45e7-906a-f8f1a6803dad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build a list of 22LR ammo manufacturers\n",
    "\n",
    "# manually built list instead of dynamically scraping each site.\n",
    "# Website-agnostic approach. Increase in speed and decrease in scraping load.\n",
    "# Missing brands can be found in df.manufacturer and entered here.\n",
    "\n",
    "list_manufacturers = [\n",
    "    'Aguila Ammunition',  # aguila is same as aquila\n",
    "    'Aquila',  # aguila is same as aquila\n",
    "    'American Eagle',\n",
    "    'Armscor',\n",
    "    'Australian Outback Ammo',\n",
    "    'Barnaul',\n",
    "    'Blaser',\n",
    "    'Blazer',\n",
    "    'Browning',\n",
    "    'Cartoucherie Française',\n",
    "    'CCI',\n",
    "    'CBC',\n",
    "    'Divers',\n",
    "    'Eley',\n",
    "    'ELD Performance',\n",
    "    'Federal',  # Federal Premium and Federal are the same\n",
    "    'Fiocchi',\n",
    "    'Flobert',\n",
    "    'Geco',\n",
    "    'Gemtech',\n",
    "    'Gevelot',\n",
    "    'Golden Eagle',\n",
    "    'Hornady',\n",
    "    'Lapua',\n",
    "    'Les Baer Custom',\n",
    "    'Lot Diverses Marques',\n",
    "    'Magtech',\n",
    "    'Manufrance',\n",
    "    'Mauser',\n",
    "    'MaxxTech',\n",
    "    'NCS',\n",
    "    'Norma',\n",
    "    'PMC',\n",
    "    'PPU',\n",
    "    'Rangemaster',\n",
    "    'Remington',\n",
    "    'RWS',\n",
    "    'Sellier and Bellot',  # Sellier & Bellot and Sellier and Bellot are the same\n",
    "    'SFM',\n",
    "    'SK',\n",
    "    'Solognac',\n",
    "    'Spartan',\n",
    "    'Speer',\n",
    "    'Topshot',\n",
    "    'Victory',\n",
    "    'Winchester',\n",
    "    'Wolf'\n",
    "]\n",
    "\n",
    "# function to search for manufacturer name in text using regex\n",
    "def search_manufacturer(text):\n",
    "    #pattern = '|'.join(list_manufacturers)\n",
    "    pattern = '|'.join([re.escape(x) for x in list_manufacturers])\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# apply search_manufacturer function to the product_name column\n",
    "df['manufacturer'] = df.apply(lambda x: search_manufacturer(x['product_name']) if pd.isna(x['manufacturer']) or x['manufacturer'] == 'N/A' else x['manufacturer'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239418a3-4442-43eb-80b4-38e923b92516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create a regex pattern to match manufacturer names from the list\n",
    "###manufacturers_pattern = re.compile(r\"\\b(\" + \"|\".join(list_manufacturers) + r\")\\b\")\n",
    "###\n",
    "#### extract manufacturer from product name or description\n",
    "###def extract_manufacturer(text):\n",
    "###    # try to extract from product name\n",
    "###    match = manufacturers_pattern.search(text)\n",
    "###    if match:\n",
    "###        return match.group(1)\n",
    "###    # if not found, try to extract from product description\n",
    "###    else:\n",
    "###        match = manufacturers_pattern.search(df.loc[df['product_name']==text, 'product_description'].values[0])\n",
    "###        if match:\n",
    "###            return match.group(1)\n",
    "###        # if still not found, return None\n",
    "###        else:\n",
    "###            return None\n",
    "###\n",
    "#### apply function to extract manufacturer from product name or description\n",
    "###df['manufacturer'] = df['product_name'].apply(extract_manufacturer)\n",
    "###\n",
    "#### check for empty cells, if any do a pass of regex on product description\n",
    "###df.loc[df['manufacturer'].isnull(), 'manufacturer'] = df['product_description'].apply(extract_manufacturer)\n",
    "###\n",
    "#### if still no data, we fill with N/A\n",
    "###df['manufacturer'].fillna('N/A', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa580d23-b1cb-4684-9c5c-118dc2690129",
   "metadata": {},
   "outputs": [],
   "source": [
    "## regex to catch any number divisible by 50 (min qtty of rounds in a box of ammo)\n",
    "#def extract_bullet_qtty(text):\n",
    "#    # match any number that is divisible by 50 without remainder\n",
    "#    regex = r\"\\b(0|[5-9]\\d*[0]|100)\\s*(?:boites de\\s*)?(?:cartouches|balles|munitions)\\b\"\n",
    "#    match = re.search(regex, text, re.IGNORECASE)\n",
    "#    if match:\n",
    "#        # extract the matched number and convert it to integer\n",
    "#        qtty = int(match.group(1))\n",
    "#        # round the quantity to the nearest 50\n",
    "#        qtty = (qtty // 50) * 50\n",
    "#        return qtty\n",
    "#    else:\n",
    "#        return None\n",
    "#\n",
    "## check titles with regex\n",
    "#df['bullet_qtty'] = df['product_name'].apply(extract_bullet_qtty)\n",
    "#\n",
    "## check for empty cells, if any do a pass of regex on product description --- !!! DUPE avoidance !!!\n",
    "#df.loc[df['bullet_qtty'].isnull(), 'bullet_qtty'] = df['product_description'].apply(extract_bullet_qtty)\n",
    "#\n",
    "## if still no data, we fill with 50 for default min number of ammo per box\n",
    "#df['bullet_qtty'].fillna(50, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf67e3-1534-4307-b033-6ae3e9cc6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to catch any number divisible by 50 (min qtty of rounds in a box of ammo)\n",
    "def extract_bullet_qtty(text):\n",
    "    # match any number that is divisible by 50 without remainder\n",
    "    regex = r\"\\b(0|[5-9]\\d*[0]|100)\\s*(?:boites de\\s*)?(?:cartouches|balles|munitions)\\b|\\bMunition \\/ boite\\s*:\\s*(0|[5-9]\\d*[0]|100)\\b\"\n",
    "    match = re.search(regex, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        # extract the matched number and convert it to integer\n",
    "        qtty = int(match.group(1)) if match.group(1) else int(match.group(2))\n",
    "        # round the quantity to the nearest 50\n",
    "        qtty = (qtty // 50) * 50\n",
    "        return qtty\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# check titles with regex\n",
    "df['bullet_qtty'] = df['product_name'].apply(extract_bullet_qtty)\n",
    "\n",
    "# check for empty cells, if any do a pass of regex on product description --- !!! DUPE avoidance !!!\n",
    "df.loc[df['bullet_qtty'].isnull(), df.columns[df.columns.get_loc('bullet_qtty')]] = df['product_description'].apply(extract_bullet_qtty)\n",
    "\n",
    "# if still no data, we fill with 50 for default min number of ammo per box\n",
    "df['bullet_qtty'].fillna(50, inplace=True)\n",
    "\n",
    "#df.sort_values('bullet_qtty', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a523b45-a29e-4101-a585-7089c034bc0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate cost of individual bullet from all data\n",
    "df[\"price_per_bullet\"] = df[\"total_price\"] / df[\"bullet_qtty\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca08ce-6333-4df8-909b-1da9ea33e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated DataFrame to CSV\n",
    "df.to_csv('naturabuy_scraped_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c522ec-2074-47b7-a577-fca1790ad7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to do\n",
    "# add scrape target - qtty of rounds. DONE\n",
    "# cost per shot DONE\n",
    "# product link DONE\n",
    "# change is_new col data to 0 and 1 DONE\n",
    "\n",
    "# df[\"QttyAmmo\"] - > regex function to run over ProductName col. Also check product_description\n",
    "# df[\"Cost_per_round\"] = df[\"TotalPrice\"] / df[\"QttyAmmo\"]\n",
    "\n",
    "# order of cols\n",
    "\n",
    "#add to price selector:\n",
    "#REGEX pattern - Munition / boite : 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1494a374-cb70-4e1e-b0f3-1ef88a511b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4e8362-87e4-4913-9b18-e273b1ddcfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
